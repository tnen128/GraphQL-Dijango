services:
  web:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    depends_on:
      db:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/simulator_db
    restart: always

  db:
    image: postgres:13
    environment:
      - POSTGRES_DB=simulator_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always

  airflow-init:
    image: apache/airflow:2.2.3
    depends_on:
      db:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://postgres:postgres@db:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__WEBSERVER__SECRET_KEY=your-very-own-secret-key-123
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__CORE__FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
    command: bash -c "
      sleep 10 &&
      airflow db init &&
      airflow users create
        --username admin
        --password admin
        --firstname Anonymous
        --lastname Admin
        --role Admin
        --email admin@example.com
      "
    restart: on-failure

  airflow-webserver:
    image: apache/airflow:2.2.3
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://postgres:postgres@db:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
      - AIRFLOW__CORE__DEFAULT_TIMEZONE=UTC
      - AIRFLOW__WEBSERVER__SECRET_KEY=your-very-own-secret-key-123
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - AIRFLOW__CORE__FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
    command: airflow webserver
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  airflow-scheduler:
    image: apache/airflow:2.2.3
    depends_on:
      - airflow-init
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
    environment:
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql://postgres:postgres@db:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=False
      - AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=10
      - AIRFLOW__SCHEDULER__DAG_FILE_PROCESSOR_TIMEOUT=600
      - AIRFLOW__SCHEDULER__PARSING_PROCESSES=2
      - AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=5
    command: airflow scheduler
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $${HOSTNAME}"]
      interval: 30s
      timeout: 30s
      retries: 3

volumes:
  postgres_data:
  airflow_logs: